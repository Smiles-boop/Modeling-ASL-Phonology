pretrained: 'pretrained_models\slgcn_16phonemes.ckpt'
data:
    modality: "pose"
    
    test_pipeline:
            parameters: {
            "handshape": "Handshape",
            "selected_fingers": "Selected Fingers",
            "flexion": "Flexion",
            "spread": "Spread",
            "spread_change": "Spread Change",
            "thumb_position": "Thumb Position",
            "thumb_contact": "Thumb Contact",
            "sign_type": "Sign Type",
            "path_movement": "Path Movement",
            "repeated_movement": "Repeated Movement",
            "major_location": "Major Location",
            "minor_location": "Minor Location",
            "second_minor_location": "Second Minor Location",
            "contact": "Contact",
            "nondominant_handshape": "Nondominant Handshape",
            "wrist_twist": "Wrist Twist",
            "handshape_morpheme_2": "Handshape Morpheme 2"
            }
            dataset:
                _target_: openhands.datasets.isolated.WLASLDataset
                root_dir: C:\Users\Adrien Chu\Modeling-ASL-Phonology\videos
                split_file: training_data\wlasl_new.json
                splits: "test"
                modality: "pose"
                inference_mode: true
            results: results\results.jsonl

            transforms:
                - PoseSelect:
                    preset: mediapipe_holistic_minimal_27
                - CenterAndScaleNormalize:
                    reference_points_preset: shoulder_mediapipe_holistic_minimal_27
                    scale_factor: 1

            dataloader:
                _target_: torch.utils.data.DataLoader
                batch_size: 32
                shuffle: false
                num_workers: 3
                pin_memory: true
                drop_last: false

model:
    encoder:
        type: decoupled-gcn
        params:
            graph_args:
                num_nodes: 27
                inward_edges:
                    [
                        [2, 0],
                        [1, 0],
                        [0, 3],
                        [0, 4],
                        [3, 5],
                        [4, 6],
                        [5, 7],
                        [6, 17],
                        [7, 8],
                        [7, 9],
                        [9, 10],
                        [7, 11],
                        [11, 12],
                        [7, 13],
                        [13, 14],
                        [7, 15],
                        [15, 16],
                        [17, 18],
                        [17, 19],
                        [19, 20],
                        [17, 21],
                        [21, 22],
                        [17, 23],
                        [23, 24],
                        [17, 25],
                        [25, 26],
                    ]
    decoder:
        type: param_fc
        params:
            dropout_ratio: 0
        parameters: 
            [
                "Handshape",
                "Selected Fingers",
                "Flexion",
                "Spread",
                "Spread Change",
                "Thumb Position",
                "Thumb Contact",
                "Sign Type",
                "Path Movement",
                "Repeated Movement",
                "Major Location",
                "Minor Location",
                "Second Minor Location",
                "Contact",
                "Nondominant Handshape", 
                "Wrist Twist",
                "Handshape Morpheme 2"
             ]


optim:
    loss: 'CrossEntropyLoss'
    optimizer:
        name: Adam
        params:
            lr: 1e-3

    scheduler:
        name: CosineAnnealingLR
        params:
            last_epoch: -1
            T_max: 10

trainer:
    gpus: 1
    max_epochs: 1000

exp_manager:
    create_tensorboard_logger: true
    create_wandb_logger: true
    wandb_logger_kwargs:
        name: model_name_here
        project: project_name_here

    create_checkpoint_callback: true
    checkpoint_callback_params:
        monitor: "val_acc"
        mode: "max"
        save_top_k: 3
        dirpath: "/pretrained_models/"

    early_stopping_callback: true
    early_stopping_params:
        monitor: "val_acc"
        patience: 80
        verbose: true
        mode: "max"
